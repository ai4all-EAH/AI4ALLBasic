{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77835ce-6cf4-44d1-9f01-dfa099f6c599",
   "metadata": {},
   "source": [
    "<img src=\"./src/logo.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9be0d-5758-460f-a7c4-44c21382c3fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Baustein:** Daten  $\\rightarrow$ **Subbaustein:** Deskriptive Statistik, Visualisierung und Datenvorverarbeitung $\\rightarrow$ **Übungsserie**\n",
    "\n",
    "**Version:** 1.0, **Lizenz:** <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">CC BY-NC-ND 4.0</a>\n",
    "\n",
    "***\n",
    "\n",
    "# Neuronale Netzwerke: Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b3797-c1f2-439b-a6a7-dfc35580ab8e",
   "metadata": {},
   "source": [
    "---\n",
    "## Importieren der notwendigen Python-Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5947d93-c31d-4249-8e00-2db917e6621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9f9145-b1ff-4d73-a872-f9ed970cf7a7",
   "metadata": {},
   "source": [
    "---\n",
    "## Importieren der Daten\n",
    "\n",
    "Im Folgenden laden wir den uns bekannten MNIST-Datensatz mit vorgefertigten Befehlen des PyTorch-Frameworks. Die Datensätze werden bei Bedarf automatisch aus dem Internet auf den JupyterHub heruntergeladen und als PyTorch-Objekt in den Arbeitsspeicher geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee04d0c-e8ea-4f24-97e8-f81f54c5aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebda6e5-5a3c-4b52-972c-ac5dc5301ff9",
   "metadata": {},
   "source": [
    "---\n",
    "Wir können uns ein beliebiges (zum Beispiel das fünfte) Bild aus dem Trainingsdatensatz anzeigen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263b54b-3bcf-4433-81e2-76afda5c950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainset[5][0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1677e-b2bd-4a91-ab85-5cd0034914e5",
   "metadata": {},
   "source": [
    "---\n",
    "#### Aufgabe 1: Machen Sie sich mit der Variable `trainset` vertraut, indem Sie sich `trainset[0]`, `trainset[1]` und `trainset[2]` (also die ersten drei Trainingsbeispiele) ausgeben lassen. Was beinhalten diese Daten genau? Schreiben Sie eine Zeile Code, die das **Label** des 20-ten Trainingsbeispieles ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf5954-e708-49a3-b1cc-1ee76de58103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e15f6038-51ad-4edc-89d8-a444c18f8890",
   "metadata": {},
   "source": [
    "---\n",
    "## Definition eines Neuronalen Netzwerkes\n",
    "\n",
    "Das Machine-Learning-Framework PyTorch erlaubt uns, Neuronale Netze im Handumdrehen zu definieren, ohne die einzelnen Berechnungen von Hand implementieren zu müssen. Im Folgenden definieren wir ein Neuronales Netzwerk, das drei Schichten hat:\n",
    "\n",
    "- eine Input-Schicht mit 784 Input-Neuronen\n",
    "- eine versteckte Schicht mit 300 Neuronen\n",
    "- eine Output-Schicht mit 10 Neuronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de2ee9-90e6-41e3-8f71-f299fb87c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219ffcf-b283-437f-81a0-036987dba509",
   "metadata": {},
   "source": [
    "---\n",
    "#### Aufgabe 2: Warum muss die Input-Schicht genau 784 Inputs bzw. Neuronen haben?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022d50c-2828-4d61-a8d8-4464119f6c8b",
   "metadata": {},
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9ab6b-d568-45c8-bfb0-818fe7416b5e",
   "metadata": {},
   "source": [
    "#### Aufgabe 3: Warum muss die Output-Schicht genau 10 Outputs bzw. Neuronen haben?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61916026-332f-4c5f-8928-30c5d8dac45d",
   "metadata": {},
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4512-65e5-4795-a547-0f32402c447c",
   "metadata": {},
   "source": [
    "---\n",
    "## Der Training-Loop\n",
    "\n",
    "Die Trainingschleife (oder Training-Loop) minimiert iterativ die Loss-Funktion bzw. den Trainingsverlust des Neuronalen Netzwerkes (siehe Vorlesung!). Dabei gibt es eine **äußere Schleife** (über die Epochen) und eine **innere Schleife** (über die Batches). Nach jedem Batch wird ein Gradientenschritt ausgeführt (`optimizer.step()`). Diese Berechnung wäre sehr aufwändig \"from scratch\" zu implementieren - zum Glück müssen wir das nicht. PyTorch bietet hierfür fertige Befehle, die maschinennah programmiert wurden. Genau dafür brauchen wir Machine-Learning-Frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41183210-b8d2-4a29-bad6-7a74283c71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss_history = np.array([])\n",
    "test_loss_history = np.array([])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        labels = nn.functional.one_hot(labels, num_classes=10).to(dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "    train_loss_av = running_loss / count\n",
    "    train_loss_history = np.append(train_loss_history, train_loss_av)\n",
    "                \n",
    "    with torch.no_grad():\n",
    "        test_loss_av = 0.0\n",
    "        count = 0\n",
    "        for data in testloader:\n",
    "            count += 1\n",
    "            images, labels = data\n",
    "            labels = nn.functional.one_hot(labels, num_classes=10).to(dtype=torch.float)\n",
    "            outputs = net(images)\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            test_loss_av += test_loss.item()\n",
    "        \n",
    "        test_loss_av = test_loss_av / count\n",
    "        test_loss_history = np.append(test_loss_history, test_loss_av)\n",
    "        \n",
    "    print('[%d] train loss: %.3f,  test loss: %.3f' % (epoch, train_loss_av, test_loss_av))\n",
    "    \n",
    "    \n",
    "print('Finished Training.')\n",
    "\n",
    "plt.plot(train_loss_history)\n",
    "plt.plot(test_loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d09fd5-9d21-4075-b79c-edf9f41429b8",
   "metadata": {},
   "source": [
    "#### Aufgabe 4: Wiederholen Sie die obenstehende Trainingsschleife, allerdings mit verschiedenen Modellarchitekturen. Variieren Sie dazu die Anzahl der Neuronen in der versteckten Schicht (aktuell 300) auf kleinere und größere Werte! Messen Sie dabei die Zeit des Trainingsverlaufes (mit Handy/Armbanduhr ist hier völlig ausreichend) und beobachten Sie den Verlauf der Loss-Kurven. Notieren und erklären Sie Ihre Beobachtungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597ceac-51dd-46d0-99ed-a888ee808538",
   "metadata": {},
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ffc9a-d6cf-4f76-8310-f9ea763c23c0",
   "metadata": {},
   "source": [
    "#### Aufgabe 5: Wiederholen Sie die obenstehende Trainingsschleife, allerdings mit einem tieferen Modell. Fügen Sie dazu dem Netzwerk eine weitere versteckte Schicht mit 50 Neuronen hinzu. Messen Sie dabei die Zeit des Trainingsverlaufes (mit Handy/Armbanduhr ist hier völlig ausreichend) und beobachten Sie den Verlauf der Loss-Kurven. Notieren und erklären Sie Ihre Beobachtungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12b22bf-3701-447f-8537-f61b14dfd6ba",
   "metadata": {},
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d25f9-b147-44db-a82e-264f75913025",
   "metadata": {},
   "source": [
    "#### Aufgabe 6: Wiederholen Sie die obenstehende Trainingsschleife, allerdings mit verschiedenen Lernraten. Variieren Sie die Lernrate (aktuell 0.001) auf kleinere und größere Werte! Wie verhält sich der Trainingsverlauf? Notieren und erklären Sie Ihre Beobachtungen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36966eba-0e3f-4e62-9ea1-dba31d088d3a",
   "metadata": {},
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64450e51-530d-455a-ae75-564979794c30",
   "metadata": {},
   "source": [
    "---\n",
    "## Auswertung\n",
    "\n",
    "Zur Evaluation des Modells betrachten wir zuerst einmal eine kleine Teilmenge aus dem Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4e003-42e4-4f77-9a42-e4d5151a32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105461b-f1bc-4a0a-88a1-f5999970385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "ncol=round(np.sqrt(1.618 * batch_size))\n",
    "\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images,nrow=ncol))\n",
    "\n",
    "classes_of_labels = [classes[labels[i]] for i in range(batch_size)]\n",
    "grouped = [classes_of_labels[i:i+ncol] for i in range(0, batch_size, ncol)]\n",
    "print(\"Testlabels (Ground Truth):\")\n",
    "for l in grouped:\n",
    "    print(\"\".join(\"{:<6}\".format(x) for x in l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5ecb5-5dd9-4403-92e3-18d219b0f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "classes_of_predictions = [classes[predicted[i]] for i in range(batch_size)]\n",
    "grouped = [classes_of_predictions[i:i+ncol] for i in range(0, batch_size, ncol)]\n",
    "print(\"Vorhersagen des Neuronalen Netzwerkes:\")\n",
    "for l in grouped:\n",
    "    print(\"\".join(\"{:<6}\".format(x) for x in l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7818464-7fc0-4cf3-ac05-21538a16848a",
   "metadata": {},
   "source": [
    "---\n",
    "Da der eine Batch aus dem Testdatensatz natürlich nicht hinreichend repräsentativ ist, betrachten wir jetzt den ganzen Testdatensatz und werten diesen in einer Wahrheitsmatrix (\"Confusion Matrix\") aus. Hierbei werden alle Klassifikationen einander gegenübergestellt und gezählt (\"Welche Ziffer wurde wie oft als was klassifiziert?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9217808-9d35-4f3b-ac00-73c16870a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(classes)\n",
    "\n",
    "conf_mat = torch.zeros((M,M), dtype=torch.int32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        labels = nn.functional.one_hot(labels, num_classes=M).to(dtype=torch.float)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        images, labels = data\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            conf_mat[label, prediction] += 1\n",
    "            \n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat.numpy(),display_labels=classes)\n",
    "disp.plot(xticks_rotation=45.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef57afb-7742-464f-bcc5-5ff638479185",
   "metadata": {},
   "source": [
    "#### Aufgabe 7: Interpretieren Sie die Confusion Matrix. Welche Ziffern werden besonders gut, welche besonders schlecht klassifiziert? Geben Sie an, welche die häufigste Verwechslung ist und stellen sie eine Vermutung an, wieso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47cc258-3a7b-42b8-b9a3-a7dce9699df9",
   "metadata": {},
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cda629-cb9d-4750-9da0-e1ece9c1647d",
   "metadata": {},
   "source": [
    "#### Aufgabe 8: Schreiben Sie ein bis fünf Zeilen Code, in denen Sie aus der Confusion Matrix (Variable `conf_mat`) die Accuracy des Neuronalen Netzwerkes berechnen. Reminder: Die Accuracy ist gleich der Summe aller Diagonalelemente geteilt durch die Summe aller Elemente der Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f68578-6507-48f1-aa79-4ef1723b1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ihr Code hier!\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfeda4e-575e-4fc4-8b60-4dec87f7a9cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Die Übungsserie begleitend zum AI4ALL-Kurs</span> der <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">EAH Jena</span> ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Namensnennung - Nicht kommerziell - Keine Bearbeitungen 4.0 International Lizenz</a>.\n",
    "\n",
    "Der AI4ALL-Kurs entsteht im Rahmen des Projekts MoVeKI2EAH. Das Projekt MoVeKI2EAH wird durch das BMBF (Bundesministerium für Bildung und Forschung) und den Freistaat Thüringen im Rahmen der Bund-Länder-Initiative zur Förderung von Künstlicher Intelligenz in der Hochschulbildung gefördert (12/2021 bis 11/2025, Föderkennzeichen 16DHBKI081)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
