{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a817d567-038e-487c-919f-555ebae3493c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "locked"
    ]
   },
   "source": [
    "<img src=\"./src/logo.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f3f46-1c14-44df-9251-878960c1fbe3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "locked"
    ]
   },
   "source": [
    "**Baustein:** Klassifikation  $\\rightarrow$ **Subbaustein:** Grundlagen und $k$-Nearest Neighbour $\\rightarrow$ **Interaktive Übungsserie**\n",
    "\n",
    "**Version:** 2.0, **Lizenz:** <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">CC BY-NC-ND 4.0</a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf124c-41f6-4482-ad19-df24145f89ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "locked"
    ]
   },
   "source": [
    "# Klassifikation: Grundlagen und $k$-Nearest Neighbour: Interaktive Übung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5acc6-bca1-4cca-931c-5fc5c260ae3d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "locked"
    ]
   },
   "source": [
    "---\n",
    "## Einleitung\n",
    "\n",
    "In dieser Übung lernen Sie die Funktionsweise und Parameter von $k$-Nearest Neighbours kennen. Als Beispiel wollen wir Pinguine des Palmer-Pinguine Datensatzes nach ihrer Art (Adelie, Chinstrap und Gentoo) klassifizieren. \n",
    "\n",
    "Um die **Auswirkungen** der einzelnen Parameter auf den $k$-Nearest Neighbours Algorithmus **testen** und **beobachten** zu können, stellen wir Ihnen ein Widget zur Verfügung. Mit diesem Widget können Sie **die folgenden Parameter einstellen**: \n",
    "\n",
    "- Register `Merkmale`: Festlegung, welche zwei Merkmale des Pinguindatensatzes zur Berechnung der $k$-Nearest Neighbours und zur Visualisierung genutzt werden sollen. Hierbei müssen immer zwei verschiedene Merkmale gewählt werden. Demnacht geht es z.B. nicht `Merkmal 1: Schnabellaenge` und `Merkmal 2: Schnabellaenge` zu wählen.\n",
    "- Register `kNN Parameter`:\n",
    "  - *`k`*: Festlegung des Parameters $k$, also wie viele Nachbarn für die Klassifikation mit einbezogen werden sollen.\n",
    "  - `Distanznorm`: Festlegung welche Distanznorm für die Berechnung der Distanzen von den $k$-Nearest Neighbours verwendet werden soll. Hier stehen die Manhattan und die Euklidische Norm zur Verfügung. \n",
    "  - `Normalisierung`: Festlegung der Normalisierung für die Vorverarbeitung der Daten für die Klassifikation. Zur Auswahl stehen \"keine\", die Min-Max-Skalierung sowie die Z-Transformation.\n",
    "  \n",
    "      Beachte: Die Visualisierung erfolgt weiterhin basierend auf den nicht normalisierten Daten und nur die Klassifikation, bzw. die Auswahl der nächsten Nachbarn wird dadurch beeinflusst.\n",
    "- Register `Testpunkt`: Festlegung der Werte der Merkmalsausprägungen für den zu klassifizierenden Testpunkt\n",
    "\n",
    "Verwenden Sie das Widget um die folgenden Aufgaben zu bearbeiten. Testen Sie hierfür jeweils verschiedene Werte für die in den Aufgaben genannten Parameter aus, um die Fragen zu beantworten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6fc07-f749-4e4d-8b70-4d301b006dfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "locked"
    ]
   },
   "outputs": [],
   "source": [
    "%run src/kNN_widget_interactive.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f88c2-39b6-4c7d-98cc-2f93d437af73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "locked"
    ]
   },
   "source": [
    "---\n",
    "## Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bf47a-dec9-4c61-98aa-2ee6522788d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "locked"
    ]
   },
   "source": [
    "## Aufgabe 1: Parameter *k*\n",
    "- Verändern Sie den Parameter $k$. Belassen Sie den Rest der Parameter bei den voreingestellten Werten. Überprüfen Sie jeweils die Ausgabe des Klassifikators für ein sehr kleines ($k=1$) und ein sehr großes $k$ ($k=260$). Erläutern Sie basierend auf Ihrer Beobachtung, wieso zu kleine oder zu große Werte für $k$ zu falschen Klassifikationen führen können.\n",
    "- Geben Sie für den Testpunkt (`Schnabellaenge: 44,05`; `Schnabelhoehe: 17,12`) einen Wert für $k$ an bei dem sich die Klassifikation von `Gentoo` auf `Chinstrap` ändert. Wieso ist die Klassifikation für diesen Testpunkt stark abhängig von dem gewählten $k$?\n",
    "- Beschreiben Sie das Verhalten des Klassifikators bei einem geraden $k$ (z.B. $k=2$)? Wieso sollte ein gerader Wert für $k$ vermieden werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152715fe-1cff-40b0-bc85-3fe8cf7b9e49",
   "metadata": {
    "deleteable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Antwort: \n",
    "- Beobachtungen bei kleinen und großen 𝑘\n",
    "    - Kleines 𝑘 (z.B. 𝑘=1):\n",
    "      Für 𝑘=1 wir nur ein Nachbar betrachtet, in dem aktuellen Fall, ist das Gentoo, obwohl die Umgebung von dem Testpunkt eigentlich eher von Chinstrap dominiert wird und der eine Gentoo Datenpunkt eventuell nicht sehr repräsentativ ist.\n",
    "      Generell lässt sich sagen, dass eine Klassifikation mit einem sehr kleinen k sehr empfindlich auf Rauschen oder Ausreißer in den Trainingsdaten reagiert.\n",
    "      Ein einzelner, zufällig falsch klassifizierter Punkt oder ein Ausreißer kann die Entscheidung des Klassifikators dominieren, also einem zu übermäßigem Fokus auf einzelnen Nachbarn (Overfitting).\n",
    "    - Großes 𝑘 (z.B. 𝑘=260):\n",
    "      Für den speziellen Fall von 𝑘=260 werden alle Datenpunkte für die Klassifikation als nächste Nachbarn gefunden unabhängig von ihrer Distanz zum Testpunkt, da es insgesamt nur 260 Datenpunkte gibt.\n",
    "      Dies führt dazu, dass der Klassifikator mehrheitlich die dominierende Klasse im gesamten Datensatz auswählt, ohne lokale Strukturen im Merkmalsraum zu berücksichtigen.\n",
    "      Generell lässt sich sagen, dass ein zu großes 𝑘 ignoriert die lokale Nachbarschaft und führt zu einer verallgemeinerten, oft falschen Klassifikation (Underfitting).\n",
    "- Änderung der Klassifikation bei spezifischem 𝑘\n",
    "    - 𝑘=1: Klassifikation Gentoo\n",
    "    - 𝑘=4: Chinstrap\n",
    "    - Der Testpunkt befindet sich in einem Bereich des Merkmalsraums, in dem sich die drei Klassen überlappen. Bei kleinen 𝑘 wird die Klasse der nächstgelegenen Nachbarn dominieren.\n",
    "      Mit wachsendem 𝑘 werden zunehmend Nachbarn aus weiter entfernten Regionen berücksichtigt, was zu einem Wechsel der dominierenden Klasse führt.\n",
    "- Verhalten bei geradem 𝑘 (z. B. 𝑘=2)\n",
    "    - Bei geraden 𝑘 kann es zu Gleichständen kommen, wenn die 𝑘-nächsten Nachbarn gleichmäßig auf verschiedene Klassen verteilt sind (z. B. 1 Nachbar aus Klasse \"Gentoo\" und 1 Nachbar aus Klasse \"Chinstrap\" bei 𝑘=2).\n",
    "      Der Klassifikator benötigt in solchen Fällen eine Regel, um den Gleichstand aufzulösen (z. B. zufällige Auswahl, Priorisierung einer Klasse). Dies kann jedoch zu inkonsistentem Verhalten führen.\n",
    "      Ein ungerades 𝑘 (z. B. 𝑘=3,5,7) garantiert eine ungerade Anzahl von Nachbarn und verhindert Gleichstände. Dadurch wird die Entscheidungsfindung stabiler und reproduzierbarer.\n",
    "      Beachte: Das gilt nur für eine binäre Klassifikationsaufgabe, in dem Beispiel hier wo es 3 Klassen gibt, kann es auch bei einem ungeraden 𝑘, wie z.B. 𝑘=3, zu Gleichständen kommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce57066-e116-4bcd-ac4d-3fb986d5783d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "locked"
    ]
   },
   "source": [
    "## Aufgabe 2: Merkmalsauswahl\n",
    "Verändern Sie `Merkmal 1` und `Merkmal 2` und testen Sie verschiedene Kombinationen. \n",
    "- Welche Merkmalskombinationen eigenen sich in Ihren Augen besonders gut zur Unterscheidung der Pinguinarten?  \r",
    "- Nennen Sie eine Merkmalskombinationen, bei der die Klassifikation besonders schlecht funktionieren könnte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe137fc-a0ac-4177-a6ac-75007e047f9e",
   "metadata": {
    "deleteable": false
   },
   "source": [
    "Antwort: \n",
    "\n",
    "Beachte: Es werden nur beispielhafte Kombinationen gegeben, keine Vollständigkeit! \n",
    "\n",
    "Zur rein visuellen Überprüfen kann man schauen, wie stark sich die Klassen im Merkmalsraum überlappen.\n",
    "- Gut geeignete Merkmalskombinationen\n",
    "    - Schnabellänge und Schnabelhöhe\n",
    "    - Schnabellänge und Verhätnis der Isotope 15N/14N\n",
    "    - Schnabellänge und Gewicht\n",
    "- Schlechter geeignete Merkmalskombinationen\n",
    "    - Flossenlänge und Schnabelhöhe (starke Überlappung im Merkmalsraum von Chinstrap und Adelie)\n",
    "    - Gewicht und Schnabelhöhe (starke Überlappung im Merkmalsraum von Chinstrap und Adelie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b85ae2-b71f-4381-9ae2-8cd6c6ba3d57",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "locked"
    ]
   },
   "source": [
    "## Aufgabe 3: Normalisierung\n",
    "Wählen Sie als `Merkmal 1: Schnabellaenge`, als `Merkmal 2: Gewicht` und für $k=51$. \n",
    "- Verändern Sie nun die Normalisierung und vergleichen Sie die Klassifikation ohne Normalisierung, mit Min-Max-Skalierung und mit Z-Transformation. \n",
    "- Erklären Sie anhand der Veränderungen, wieso für eine Klassifikation mit $k$-Nearest Neighbours eine vorhergehende Normalisierung der Daten sinnvoll ist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc586ecf-6fef-4cb3-884e-7f89ea537f37",
   "metadata": {
    "deleteable": false
   },
   "source": [
    "Antwort: \n",
    "\n",
    "Ohne Normalisierung sind die Abstände zwischen den Werten der Merkmale nicht vergleichbar, da sie unterschiedliche Wertebereiche haben. Zum Beispiel variiert die Schnabellänge nur zwischen 30 und 60 mm, während das Gewicht zwischen 2500 und 6500 g liegt.\n",
    "\n",
    "Eine Einheit in Richtung Schnabellänge (z.B. 1 mm) stellt im Verhältnis zur Gesamtspanne der Schnabellänge einen deutlich größeren Schritt dar als eine Einheit in Richtung Gewicht (1 g), die im Vergleich zur Gesamtspanne des Gewichts kaum ins Gewicht fällt.\n",
    "\n",
    "Ohne Normalisierung wird dadurch die Distanz in Richtung Gewicht nahezu ignoriert, und die Klassifikation basiert fast ausschließlich auf der Schnabellänge. Normalisierung stellt sicher, dass beide Merkmale gleichberechtigt in die Distanzberechnung eingehen.\n",
    "\n",
    "- Ohne Normalisierung: Verzerrte Ergebnisse, Dominanz bestimmter Merkmale\n",
    "- Min-Max-Skalierung: Skaliert Daten auf denselben Wertebereich, verhindert Dominanz eines Merkmals, ist jedoch anfällig für Ausreißer.\n",
    "- Z-Transformation: Zentriert die Daten und macht sie dimensionslos, robuster gegenüber Ausreißern, sinnvoll bei normalverteilten Daten.\n",
    "\n",
    "Fazit: Eine Normalisierung ist für 𝑘-Nearest Neighbors zwingend erforderlich, um sicherzustellen, dass alle Merkmale gleich in die Klassifikation eingehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2778c7-a184-4486-96a8-b40699f91ffa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "locked"
    ]
   },
   "source": [
    "## Aufgabe 4: Distanzmaße\n",
    "Wählen Sie für diese Aufgabe $k=40$ und keine Normalisierung.\n",
    "- Wählen Sie verschiedene Testpunkt und vergleichen Sie für diese die Manhattan-Distanz mit der euklidischen Distanz.\n",
    "- Welches Distanzmaß ist für Sie intuitiver?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1477c-ba7d-4355-a7f0-e1f0d33a79e3",
   "metadata": {
    "deleteable": false
   },
   "source": [
    "Antwort: \n",
    "\n",
    "- Die euklidische Distanz für viele intuitiver, da sie die direkte, geometrische Entfernung berücksichtigt.\n",
    "- Die Manhattan-Distanz kann jedoch sinnvoller sein, wenn die Daten entlang separater Dimensionen oder in einer \"rasterartigen\" Struktur vorliegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db146e-4ace-4f70-9624-2bcefe7c2889",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "locked"
    ]
   },
   "source": [
    "---\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Die Übungsserie begleitend zum AI4ALL-Kurs</span> der <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">EAH Jena</span> ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Namensnennung - Nicht kommerziell - Keine Bearbeitungen 4.0 International Lizenz</a>.\n",
    "\n",
    "Der AI4ALL-Kurs entsteht im Rahmen des Projekts MoVeKI2EAH. Das Projekt MoVeKI2EAH wird durch das BMBF (Bundesministerium für Bildung und Forschung) und den Freistaat Thüringen im Rahmen der Bund-Länder-Initiative zur Förderung von Künstlicher Intelligenz in der Hochschulbildung gefördert (12/2021 bis 11/2025, Föderkennzeichen 16DHBKI081)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
