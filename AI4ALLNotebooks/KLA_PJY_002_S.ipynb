{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./src/logo.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baustein:** Klassifikation  $\\rightarrow$ **Subbaustein:** Grundlagen und $k$-Nearest Neighbour $\\rightarrow$ **Übungsserie**\n",
    "\n",
    "**Version:** 2.0, **Lizenz:** <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">CC BY-NC-ND 4.0</a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation 1: Grundlagen und $k$-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Übung werden wir den palmerpenguins Datensatz verwenden, den Sie in der Vorlesung und Übung zu \"Daten– Deskriptive Statistik und Visualisierung\" bereits kennengelernt haben. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Einführung\n",
    "\n",
    "Bitte bearbeiten Sie die interaktive Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Daten in Trainings- und Testdaten aufteilen\n",
    "\n",
    "Wir wollen nun den Datensatz in Trainings- und Testdaten aufteilen, um ein Modell zu trainieren und anschließend zu evaluieren. Dafür verwenden wir die Funktion train_test_split aus der Bibliothek sklearn.model_selection. Bitte importieren Sie dazu zu Beginn das Paket pandas und train_test_split aus der Bibliothek sklearn.model_selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Lesen Sie den Datensatz penguins.csv mit pandas und der Methode .read_csv() ein. Sie finden den Datensatz in Moodle unter Daten/Klassifikation. Lassen Sie sich danach mit .head() die ersten 5 Zeilen ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Bitte bereinigen Sie den Datensatz um fehlende Werte. Verwenden Sie die Methode .dropna(), um alle Zeilen mit fehlenden Werten zu entfernen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Definieren Sie nun die unabhängigen Variablen (Features) und die Zielvariable (Zielvariable) in Form von jeweils einer Liste. Für die die Features (X) wählen Sie die numerischen Spalten: Schnabellaenge, Schnabelhoehe, Flossenlaenge, Gewicht und für die Zielvariable (y) wählen Sie die Spalte Pinguinart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Teilen Sie nun die Daten mithilfe von train_test_split in Trainings- und Testdatensätze auf. Verwenden Sie dazu die Funktion train_test_split mit folgenden Parametern:\n",
    "test_size=0.2: 20% der Daten werden für das Testset, random_state=42: Sorgt dafür, dass die Aufteilung bei jedem Lauf gleich bleibt.\n",
    "Speichern Sie dann die Ergebnisse in die Variablen X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Überprüfen Sie nun die Größe der aufgeteilten Datensätze, um sicherzustellen, dass die Aufteilung korrekt war. Verwenden Sie dazu die Methode .shape() auf X_train, X_test, y_train und y_test. Geben Sie anschliessend die Ergebnisse aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: kNeighborsClassifier erzeugen und trainieren\n",
    "\n",
    "Wir wollen nun ein k-Nearest Neighbors (kNN) Modell erzeugen, trainieren und evaluieren. Bitte importieren Sie dazu zu Beginn das Paket KNeighborsClassifier aus der Bibliothek sklearn.neighbors.\n",
    "\n",
    "3.1 Erzeugen Sie ein kNN-Modell mit \\(k=3\\).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Trainieren Sie nun ihr Modell mit den Trainingsdaten. Verwenden Sie dazu die Methode .fit() mit den Trainingsdaten X_train und y_train. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Verwenden Sie nun das trainierte Modell, um Vorhersagen für die Testdaten zu treffen. Wenden Sie dazu die Methode .predict() auf die Testdaten X_test an. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Berechnen Sie die Genauigkeit des Modells auf den Testdaten, um zu prüfen, wie gut das Modell funktioniert. Verwenden Sie dazu die Methode .score() und übergeben Sie die Testdaten X_test und die Zielwerte y_test. Geben Sie die Genauigkeit mit einem erklärenden Text aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4: Modell testen und Ergebnisse ausgeben\n",
    "\n",
    "Nachdem das kNN-Modell trainiert wurde, wollen wir testen, wie gut es funktioniert. Dazu wenden wir das Modell auf die Testdaten an und vergleichen die Vorhersagen mit den tatsächlichen Klassen. So können wir beurteilen, wie genau das Modell arbeitet.\n",
    "\n",
    "4.1 Treffen Sie nun mit dem trainierten Modell Vorhersagen für die Testdaten. Verwenden Sie dazu die Methode .predict() und übergeben Sie X_test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Um die Modellleistung besser zu verstehen, vergleichen Sie die Vorhersagen y_pred direkt mit den tatsächlichen Klassenwerten y_test. Geben Sie die ersten 10 Werte aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5: Modell mit verschiedenen $k$ trainieren und bewerten\n",
    "\n",
    "Nun untersuchen wir, wie die Wahl von $k$ die Leistung des kNN-Modells beeinflusst. Die Wahl von $k$ ist entscheidend für die Balance zwischen Überanpassung (Overfitting) und Unteranpassung (Underfitting):\n",
    "\n",
    "- Kleines $k$: Das Modell reagiert sehr stark auf einzelne Nachbarn, was zu Überanpassung führen kann. Es kann gut auf den Trainingsdaten abschneiden, aber schlecht auf den Testdaten generalisieren.\n",
    "- Großes $k$: Das Modell berücksichtigt viele Nachbarn, was die Vorhersagen glättet. Ein zu großes $k$ kann dazu führen, dass wichtige lokale Strukturen ignoriert werden, was zu Unteranpassung führt.\n",
    "\n",
    "5.1 Erstellen Sie zwei neue kNN-Modelle mit unterschiedlichen Werten für $k$:\n",
    "- Modell 1: Mit $k$=4, um ein relativ kleines $k$ zu testen.\n",
    "- Modell 2: Mit $k$=7, um ein etwas größeres $k$ zu testen.\n",
    "\n",
    "Trainieren Sie beide Modelle mit den Trainingsdaten (X_train, y_train). Verwenden Sie die Methode .fit() für beide Modelle. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Bewerten Sie die Modelle, indem Sie sie auf den Testdaten anwenden und die Genauigkeit für jedes Modell berechnen. Verwenden Sie die Methode .score() für jedes Modell, um die Genauigkeit auf den Testdaten X_test und y_test zu berechnen. Geben Sie die Genauigkeiten der beiden Modelle aus und vergleichen Sie die Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 6: Andere Distanzmetriken nutzen\n",
    "Die Wahl der **Distanzmetrik** kann die Vorhersagen des Modells erheblich beeinflussen, da sie bestimmt, wie der Abstand zwischen den Datenpunkten berechnet wird.\n",
    "\n",
    "Nun untersuchen wir, wie sich unterschiedliche Distanzmetriken auf die Leistung des kNN-Modells auswirken. Standardmäßig verwendet der KNeighborsClassifier die **euklidische Distanz** (p=2). Wir möchten dies mit der **Manhattan-Distanz** (p=1) vergleichen. \n",
    "\n",
    "6.1 Erstellen Sie ein kNN-Modell mit Manhattan-Distanz. Passen Sie die Distanzmetrik des kNN-Modells an, indem Sie den Parameter p=1 verwenden. Dies sorgt dafür, dass das Modell die Manhattan-Distanz verwendet. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Trainieren Sie das Modell mit den Trainingsdaten (X_train, y_train). Verwenden Sie die Methode .fit() und übergeben Sie X_train und y_train als Argumente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Berechnen Sie die Genauigkeit des Modells auf den Testdaten und vergleichen Sie diese mit dem Modell, das die euklidische Distanz verwendet (p=2). Verwenden Sie dazu die Methode .score() des Modells mit Manhattan-Distanz und berechnen Sie die Genauigkeit. Berechnen Sie auch die Genauigkeit des Modells mit euklidischer Distanz, falls diese noch nicht ermittelt wurde. Vergleichen Sie die beiden Werte und geben sie diese aus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 Überlegen Sie: Welche Distanzmetrik liefert die bessere Genauigkeit? Ist die Genauigkeit mit Manhattan-Distanz höher oder niedriger als mit euklidischer Distanz? Warum könnte eine Distanzmetrik in manchen Fällen besser geeignet sein als die andere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 7: Trainingsdaten skalieren\n",
    "\n",
    "Nun skalieren wir die Daten mithilfe eines StandardScaler, um sie zu standardisieren (Mittelwert 0, Standardabweichung 1). Dabei wird der Scaler auf den **Trainingsdaten angepasst** und gespeichert, damit er später auf die Testdaten angewendet werden kann.\n",
    "\n",
    "7.1 Bitte führen Sie die folgenden Codes aus, welche eine unterschideliche Vorgehensweise der Standardisierung der Trainingsdaten vornehmen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erste 5 Zeilen der skalierten Trainingsdaten (Variante 1):\n",
      "[[-1.47420614 -0.01175645 -1.02305926 -0.63891919]\n",
      " [ 1.08811257 -0.97970446  1.20026301  1.83751179]\n",
      " [-1.43760158  0.09013281 -1.02305926 -1.13420539]\n",
      " [-0.28455816  0.09013281 -1.02305926 -1.07229462]\n",
      " [-1.6572289   0.3958006  -0.80789904 -0.94847307]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Daten einlesen\n",
    "data = pd.read_csv('data/penguins.csv')  \n",
    "\n",
    "# Datenbereinigung: Entfernen von fehlenden Werten\n",
    "data = data.dropna()\n",
    "\n",
    "# Variablen definieren\n",
    "# Auswahl der Features und der Zielvariable\n",
    "X = data[['Schnabellaenge', 'Schnabelhoehe', 'Flossenlaenge', 'Gewicht']]\n",
    "y = data['Pinguinart']\n",
    "\n",
    "# Standardisierung vor der Aufteilung\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Aufteilung der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Überprüfen der skalierten Daten\n",
    "print(\"Erste 5 Zeilen der skalierten Trainingsdaten (Variante 1):\")\n",
    "print(X_train[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erste 5 Zeilen der skalierten Trainingsdaten (Variante 2):\n",
      "[[-1.48374356  0.02372863 -0.981962   -0.63433333]\n",
      " [ 1.07949683 -0.96032518  1.17070673  1.80934365]\n",
      " [-1.44712584  0.12731325 -0.981962   -1.12306873]\n",
      " [-0.29366766  0.12731325 -0.981962   -1.0619768 ]\n",
      " [-1.66683216  0.43806708 -0.77363922 -0.93979295]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Daten einlesen\n",
    "data = pd.read_csv('data/penguins.csv')  \n",
    "\n",
    "# Datenbereinigung: Entfernen von fehlenden Werten\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Auswahl der Features und der Zielvariable\n",
    "X = data[['Schnabellaenge', 'Schnabelhoehe', 'Flossenlaenge', 'Gewicht']]\n",
    "y = data['Pinguinart']\n",
    "\n",
    "# Aufteilung der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# StandardScaler erstellen\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaler auf die Trainingsdaten anpassen und transformieren\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scaler speichern\n",
    "saved_scaler = scaler\n",
    "\n",
    "# Überprüfen der skalierten Trainingsdaten\n",
    "print(\"Erste 5 Zeilen der skalierten Trainingsdaten (Variante 2):\")\n",
    "print(X_train_scaled[:5])\n",
    "\n",
    "# Testdaten mit dem gespeicherten Scaler transformieren\n",
    "X_test_scaled = saved_scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Bitte versuchen, Sie jeden Schritt nachzuvollziehen. Warum ist es wichtig, dass die Standardisierungsparameter (z. B. Mittelwert und Standardabweichung) ausschließlich aus\n",
    "den Trainingsdaten berechnet werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 8: Den kNN mit skalierten Daten trainieren\n",
    "\n",
    "Nun verwenden wir die skalierten Daten, um das kNN-Modell erneut zu trainieren. \n",
    "\n",
    "7.1 Trainieren Sie nun das kNN-Modell mit $k$=3 erneut auf den skalierten Trainingsdaten aus Aufgabe 6. Verwenden Sie KNeighborsClassifier(n_neighbors=3), um ein kNN-Modell mit 3 Nachbarn zu initialisieren. Wenden Sie die Methode .fit() auf die skalierten Trainingsdaten X_train_scaled und die Zielvariable y_train an. \n",
    "\n",
    "Nun wenden wir den **zuvor auf die Trainingsdaten angepassten** Scaler aus Variante 2 auf die Testdaten an. Dies stellt sicher, dass die Testdaten **genauso skaliert** werden wie die Trainingsdaten. Anschließend testen wir das kNN-Modell mit den skalierten Testdaten und bewerten die Genauigkeit.\n",
    "\n",
    "---\n",
    "\n",
    "**Warum passen wir den Scaler nur auf die Trainingsdaten an?**\n",
    "\n",
    "1. Vermeidung von Datenlecks: \n",
    "   Wenn wir den Scaler auf die Testdaten anpassen würden, fließen Informationen aus den Testdaten in den Trainingsprozess ein. Dies würde zu einem sogenannten *Datenleck* führen, bei dem das Modell Informationen erhält, die es in der Realität noch nicht kennen sollte. Dies führt zu einer übertrieben optimistischen Einschätzung der Modellleistung. Um die Generalisierungsfähigkeit des Modells korrekt zu bewerten, werden die Testdaten während des Trainings nicht \"berührt\". Der Scaler wird also nur auf die Trainingsdaten angepasst und dann ohne erneute Anpassung auf die Testdaten angewendet.\n",
    "\n",
    "2. Konsistente Skalierung:  \n",
    "   Der Scaler, der anhand der Trainingsdaten Mittelwert und Standardabweichung berechnet hat, wird verwendet, um die Testdaten mit denselben Parametern zu transformieren. So wird sichergestellt, dass sowohl Trainings- als auch Testdaten in derselben Skala vorliegen, was für die korrekte Modellinterpretation entscheidend ist.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Verwenden Sie den zuvor gespeicherten Scaler (scaler), um die Testdaten X_test zu skalieren. Nutzen Sie dazu die Methode .transform().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Wenden Sie die Methode .score() des trainierten kNN-Modells (knn_scaled) an, um die Genauigkeit auf den skalierten Testdaten X_test_scaled und den tatsächlichen Klassen y_test zu berechnen und geben Sie die Genauigkeit in Prozent aus, um die Modellleistung auf den skalierten Testdaten zu bewerten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 9: Confusion Matrix darstellen\n",
    "\n",
    "\n",
    "9.1 Berechnen Sie die Confusion Matrix: Verwenden Sie confusion_matrix() mit den tatsächlichen Werten y_test und den Vorhersagen des Modells auf X_test_scaled.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Visualisieren Sie die Confusion Matrix: Nutzen Sie seaborn.heatmap(), um die Confusion Matrix als Heatmap darzustellen. Beschriften Sie die Achsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 10: Anderen Datensatz verwenden\n",
    "\n",
    "Als Abschlussaufgabe können Sie nun einen anderen Datensatz verwenden und die gleichen Schritte wie zuvor anwenden. Sie sollten in der Lage sein, ein kNN-Modell auf jedem beliebigen Klassifikationsdatensatz anzuwenden.\n",
    "\n",
    "### Schritte:\n",
    "1. Wählen Sie einen anderen Datensatz aus der Liste.\n",
    "2. Laden Sie die Daten und teilen Sie sie in Trainings- und Testdaten auf.\n",
    "3. Skalieren Sie die Daten bei Bedarf.\n",
    "4. Trainieren und testen Sie das kNN-Modell mit verschiedenen Werten für $k$ und unterschiedlichen Distanzmetriken.\n",
    "5. Bestimmen Sie das beste Modell basierend auf den Ergebnissen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verfügbare Datensätze sind:\n",
    "\n",
    "| Art                                                                                                                  | Name                  |\n",
    "|----------------------------------------------------------------------------------------------------------------------|-----------------------|\n",
    "| [Pflanzempfehlungen](https://www.kaggle.com/datasets/chitrakumari25/smart-agricultural-production-optimizing-engine) | pflanzempfehlung.csv      |\n",
    "| [Herzinfarkt-Risiko](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)    | herzinfarkt.csv           |\n",
    "| [Kickstarter-Projekte](https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects)                      | kickstarter.csv           |\n",
    "| [Krebs-Klassifikation](https://www.kaggle.com/datasets/erdemtaha/cancer-data)                                        | krebs.csv                 |\n",
    "| [Glass-Identifikation](https://www.kaggle.com/datasets/prashant111/glass-identification-dataset)                     | glas.csv                  |\n",
    "| [Kundenpersönlichkeits-Analyse](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis)           | kundenpersoenlichkeit.csv |\n",
    "| [Pinguin-Klassifikation](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data)     | penguins.csv              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lösung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Die Übungsserie begleitend zum AI4ALL-Kurs</span> der <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">EAH Jena</span> ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Namensnennung - Nicht kommerziell - Keine Bearbeitungen 4.0 International Lizenz</a>.\n",
    "\n",
    "Der AI4ALL-Kurs entsteht im Rahmen des Projekts MoVeKI2EAH. Das Projekt MoVeKI2EAH wird durch das BMBF (Bundesministerium für Bildung und Forschung) und den Freistaat Thüringen im Rahmen der Bund-Länder-Initiative zur Förderung von Künstlicher Intelligenz in der Hochschulbildung gefördert (12/2021 bis 11/2025, Föderkennzeichen 16DHBKI081)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
